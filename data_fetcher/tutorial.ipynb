{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据获取部分教程\n",
    "\n",
    "### 任务要求：\n",
    " * 创建一个名为`hello_world`的文献集\n",
    " * 分别在IEEE以\"good evening\"为检索词，在Scopus以\"good morning\"为检索词，获取检索结果前5条（两个数据源共10条）文献元数据，加入`hello_world`文献集\n",
    " * 获取这10篇文献的原文，保存在`./data/stay_home`目录下，并将每篇文献的原文地址记录在元数据中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行初始化，创建一些基础对象\n",
    "import os\n",
    "os.chdir('D:\\\\大三下\\\\a\\\\系统\\\\Project-KnowNet')\n",
    "from data_fetcher.id_manager import IDManager\n",
    "from data_platform.config import ConfigManager\n",
    "from data_platform.datasource.mongodb import MongoDBDS\n",
    "from pathlib import Path\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "current_location = Path(os.getcwd())\n",
    "config = ConfigManager({\n",
    "    'init':{\n",
    "        'uri': None,\n",
    "        'database': 'db'\n",
    "    }\n",
    "})\n",
    "\n",
    "mgdbds = MongoDBDS(config=config)\n",
    "# 先将数据库原有内容清空\n",
    "mgdbds.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个ID管理器，用于给文献赋ID\n",
    "pim = IDManager(\n",
    "    config=config, \n",
    "    key=('paper_id', 'title'), \n",
    "    auto_inc = ('id_inc', 'paper_id')\n",
    ")\n",
    "\n",
    "print(mgdbds.get_db().list_collection_names())\n",
    "print(list(mgdbds.get_db()['id_inc'].find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先爬IEEE\n",
    "from data_fetcher.ieee.ieee_retrieval import IEEERetrieval\n",
    "ir = IEEERetrieval(\n",
    "    query = 'good evening',\n",
    "    offset = 0,\n",
    "    num_result = 5, \n",
    "    paper_id_manager=pim,\n",
    "    paper_set='hello_world'\n",
    ")\n",
    "ir_res = ir.retrieve()     # 执行检索\n",
    "ir.save(mgdbds)         # 将检索结果记录在数据库中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from data_fetcher.ieee.ieee_fulltext_spider import IEEEFulltextSpider\n",
    "\n",
    "article_numbers = [item['IEEEArticleNumber'] for item in ir_res]\n",
    "\n",
    "for article_number in article_numbers:\n",
    "    # 请注意：一定要在校园网环境下爬才能成功！\n",
    "    ifs = IEEEFulltextSpider(\n",
    "        article_number=article_number,\n",
    "        request_interval=5\n",
    "    )\n",
    "    ifs_result = ifs.execute() # 爬取PDF，记录爬取结果所在路径\n",
    "    # 当然并不是所有原文都能成功爬到的，爬不到就会输出ERROR的log\n",
    "    \n",
    "    # 更新数据库中对应元数据的uri字段。\n",
    "    # 可以整合到FullTextSpider类中，但这样会增加耦合，所以我还在思考\n",
    "    if ifs_result:\n",
    "        mgdbds.query_and_update_doc(\n",
    "            docset='metadata',\n",
    "            query={'IEEEArticleNumber': article_number},\n",
    "            val={'$set': {'uri': ifs_result}}\n",
    "        )\n",
    "    # 另外以后可以考虑改成多线程，这样爬IEEE的时候还能继续运行后面的程序\n",
    "\n",
    "# 此时./data中应该已经有几篇pdf了。\n",
    "# 检查现在数据库中的内容\n",
    "print(mgdbds.get_db().list_collection_names())\n",
    "print(list(mgdbds.get_db()['paper_id'].find()))\n",
    "print(list(mgdbds.get_db()['paper_set'].find()))\n",
    "print(list(mgdbds.get_db()['metadata'].find())[-1]) # 注意uri字段\n",
    "print(list(mgdbds.get_db()['id_inc'].find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再爬Scopus\n",
    "from data_fetcher.scopus.scopus_retrieval import ScopusRetrieval\n",
    "\n",
    "# 爬之前要先在./data_fetcher/scopus路径下设置config文件，详见./data_fetcher/README.md\n",
    "sr = ScopusRetrieval(query='good morning', num_result=5)  # 初始化Scopus检索接口类\n",
    "sr.retrieve()       # 执行检索\n",
    "sr_doi_list = sr.get_doi_list()     # 获取检索结果中的doi，方便后续爬元数据和全文\n",
    "print(sr_doi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from data_fetcher.scopus.scopus_metadata_spider import ScopusMetadataSpider\n",
    "from data_fetcher.scopus.scopus_fulltext_spider import ScopusFulltextSpider\n",
    "\n",
    "for sr_doi in sr_doi_list:\n",
    "    # 爬元数据\n",
    "    sms = ScopusMetadataSpider(\n",
    "        doi=sr_doi,\n",
    "        paper_id_manager=pim,\n",
    "        paper_set='hello_world'\n",
    "    )\n",
    "    sms_result = sms.execute()\n",
    "    sms.save(mgdbds)\n",
    "\n",
    "    # 爬全文，更新元数据\n",
    "    # 有的文章可能没收录全文。\n",
    "    # 请注意：一定要在校园网环境下爬才能成功！\n",
    "    # 当然并不是所有原文都能成功爬到的，爬不到会返回表示错误的json: \n",
    "    # {\"status\":{\"statusCode\":\"RESOURCE_NOT_FOUND\",\"statusText\":\"The resource specified cannot be found.\"}\n",
    "    sfs = ScopusFulltextSpider(doi=sr_doi) \n",
    "    sfs_result = sfs.execute()\n",
    "\n",
    "    if sfs_result:\n",
    "         mgdbds.query_and_update_doc(\n",
    "            docset='metadata',\n",
    "            query={'doi': sr_doi},\n",
    "            val={'$set': {'uri': sfs_result}}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终检查数据库内容\n",
    "print(mgdbds.get_db().list_collection_names())\n",
    "print(list(mgdbds.get_db()['id_inc'].find()))\n",
    "print(list(mgdbds.get_db()['paper_set'].find()))\n",
    "# 都打印出来太长了，看个总数就行\n",
    "print(len(list(mgdbds.get_db()['paper_id'].find())))\n",
    "print(len(list(mgdbds.get_db()['metadata'].find())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们还要把good morning检索到的元数据添加到另一个\"hello_python\" paper_set中。\n",
    "# 爬虫是无需知道这些元数据是否已经在metadata集合或某个paper_set中出现过的（当然以后可以加上查重功能）\n",
    "# 因此会先爬一遍，再保存到metadata集合，再加入到\"hello_python\" paper_set。\n",
    "\n",
    "from data_fetcher.scopus.scopus_metadata_spider import ScopusMetadataSpider\n",
    "from data_fetcher.scopus.scopus_fulltext_spider import ScopusFulltextSpider\n",
    "\n",
    "for sr_doi in sr_doi_list:\n",
    "    # 爬元数据\n",
    "    sms = ScopusMetadataSpider(\n",
    "        doi=sr_doi,\n",
    "        paper_id_manager=pim,\n",
    "        paper_set='hello_python'\n",
    "    )\n",
    "    sms_result = sms.execute()\n",
    "    sms.save(mgdbds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终检查数据库内容\n",
    "print(mgdbds.get_db().list_collection_names())\n",
    "print(list(mgdbds.get_db()['id_inc'].find()))\n",
    "print(list(mgdbds.get_db()['paper_set'].find()))\n",
    "# 都打印出来太长了，看个总数就行\n",
    "print(len(list(mgdbds.get_db()['paper_id'].find())))\n",
    "print(len(list(mgdbds.get_db()['metadata'].find())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2.0,
  "kernelspec": {
   "name": "python36764bitd53fb91182864ec1a5d6e5d91f768daf",
   "display_name": "Python 3.6.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
